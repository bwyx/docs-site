(window.webpackJsonp=window.webpackJsonp||[]).push([[14],{378:function(e,t,a){"use strict";a.r(t);var r=a(45),s=Object(r.a)({},(function(){var e=this,t=e.$createElement,a=e._self._c||t;return a("ContentSlotsDistributor",{attrs:{"slot-key":e.$parent.slotKey}},[a("h1",{attrs:{id:"terraform-templates"}},[a("a",{staticClass:"header-anchor",attrs:{href:"#terraform-templates"}},[e._v("#")]),e._v(" Terraform Templates")]),e._v(" "),a("div",{staticClass:"custom-block warning"},[a("p",{staticClass:"custom-block-title"},[e._v("WARNING")]),e._v(" "),a("p",[e._v("Template structure is subject to changing in future versions of digger")])]),e._v(" "),a("p",[e._v("Digger templates are not much different from standard terraform. We use jinja2 under the hood to pass configuration parameters to these templates. The flow is summarised in the visual bellow. Options flow from the digger.yml, along with additional environment options, directly into a template store in a github repository. These are used to render terraform which can be applied in the user's account.")]),e._v(" "),a("p",[a("img",{attrs:{src:"https://i.imgur.com/I82kCkX.png",alt:""}})]),e._v(" "),a("h3",{attrs:{id:"directory-structure"}},[a("a",{staticClass:"header-anchor",attrs:{href:"#directory-structure"}},[e._v("#")]),e._v(" Directory Structure")]),e._v(" "),a("p",[e._v("The directory structure of digger templates looks similar to terraform. We run the main files under the "),a("code",[e._v("main/")]),e._v(" directory. You can see an example terraform template for fargate in this "),a("a",{attrs:{href:"https://github.com/diggerhq/target-fargate/tree/example",target:"_blank",rel:"noopener noreferrer"}},[e._v("example repository"),a("OutboundLink")],1)]),e._v(" "),a("div",{staticClass:"language- extra-class"},[a("pre",{pre:!0,attrs:{class:"language-text"}},[a("code",[e._v("main/\n   file1.tf\n   file2.tf\n   service.template.tf\nmodule1/\nmodule2/\nbackend_s3.template.conf\nterraform.template.tfvars\n")])])]),a("p",[e._v("Bellow the main components of a digger templates are explained:")]),e._v(" "),a("p",[a("strong",[e._v("main/")]),e._v(': The terraform apply command is run in this context and hence all the .tf files will be included in the generated infrastructure. Any file with the suffix "*.template.tf" is rendered to a .tf file before the apply and therefore you can use standard jinja template tags {{}} in these files.')]),e._v(" "),a("p",[a("strong",[e._v("service.template.tf")]),e._v(": This is a special file that is rendered multiple times for each service entry in the digger.yml file. For example, if we have two services svc1 and svc2, we will end up with service-svc1.tf and service-svc2.tf. Each file will be able to use the service options as standard {{}} jinja templates.")]),e._v(" "),a("p",[a("strong",[e._v("module/")]),e._v(": you can use either local or remote modules as supported by terraform. For local modules you can have these as sister folders and refer to them directly.")]),e._v(" "),a("h3",{attrs:{id:"using-terraform-variables"}},[a("a",{staticClass:"header-anchor",attrs:{href:"#using-terraform-variables"}},[e._v("#")]),e._v(" Using Terraform variables")]),e._v(" "),a("p",[e._v("If you want to use terraform variables, define them in your "),a("code",[e._v("variables.tf")]),e._v(" file or elsewhere in your main/*.tf files. After that you need to assign values to these variables if they don't have a default value. You can do this in the file "),a("a",{attrs:{href:"https://github.com/diggerhq/target-fargate/blob/example/terraform.template.tfvars",target:"_blank",rel:"noopener noreferrer"}},[e._v("terraform.template.tfvars"),a("OutboundLink")],1)]),e._v(" "),a("h3",{attrs:{id:"outputs"}},[a("a",{staticClass:"header-anchor",attrs:{href:"#outputs"}},[e._v("#")]),e._v(" Outputs")]),e._v(" "),a("p",[e._v("You can specify outputs anywhere in your template files. By convention it is nice to have all template outputs in a file called "),a("code",[e._v("outputs.tf")]),e._v(". All terraform outputs will be exposable after an "),a("code",[e._v("env apply")]),e._v(" command. To show terraform outputs for an environment, you can run "),a("code",[e._v("dg env describe env_name")])]),e._v(" "),a("h3",{attrs:{id:"mapping-outputs-to-environment-variables"}},[a("a",{staticClass:"header-anchor",attrs:{href:"#mapping-outputs-to-environment-variables"}},[e._v("#")]),e._v(" Mapping outputs to Environment Variables")]),e._v(" "),a("p",[e._v("Any output which starts "),a("code",[e._v("DGVAR_")]),e._v(" prefix will be mapped to an environment variable on release.")]),e._v(" "),a("h3",{attrs:{id:"mapping-outputs-to-secrets"}},[a("a",{staticClass:"header-anchor",attrs:{href:"#mapping-outputs-to-secrets"}},[e._v("#")]),e._v(" Mapping outputs to secrets")]),e._v(" "),a("p",[e._v("To integrate with Parameter store secrets, create an entry of the secret value and then output the value of it using "),a("code",[e._v("DGVAR_")]),e._v(" prefix as mentioned above. Here is an example: "),a("a",{attrs:{href:"https://github.com/diggerhq/target-fargate/blob/example/main/database.template.tf#L43",target:"_blank",rel:"noopener noreferrer"}},[e._v("database password"),a("OutboundLink")],1),e._v(" in parameter store mapped to "),a("a",{attrs:{href:"https://github.com/diggerhq/target-fargate/blob/example/main/outputs.template.tf#L40",target:"_blank",rel:"noopener noreferrer"}},[e._v("outputs"),a("OutboundLink")],1),e._v(" using its arn value:")]),e._v(" "),a("div",{staticClass:"language- extra-class"},[a("pre",{pre:!0,attrs:{class:"language-text"}},[a("code",[e._v('resource "aws_ssm_parameter" "database_password" {\n    name = "${var.app}.${var.environment}.rds.database_password"\n    value = local.database_password\n    type = "SecureString"\n}\n\n#...\n\n# to output a secret, simply output the ARN value of a parameter store\noutput "DGVAR_POSTGRES_PASSWORD" {\n    value = aws_ssm_parameter.database_password.arn\n    sensitive = true\n}\n')])])]),a("h3",{attrs:{id:"a-note-on-unique-naming"}},[a("a",{staticClass:"header-anchor",attrs:{href:"#a-note-on-unique-naming"}},[e._v("#")]),e._v(" A note on unique naming")]),e._v(" "),a("p",[e._v("Some resources such as S3 buckets have to be unique globally. In addition, we want to avoid having naming conflicts of resources such as ECS clusters.")]),e._v(" "),a("p",[e._v("In Digger, project names are unique globally. Therefore if you want to gaurantee unique names of your resources across environments is to use project_name_environment_name patterns. With that said, many terraform resources also support a name_prefix attribute which gaurantee uniqueness. It is good to make use of this name_prefix attribute to avoid problems since in this case terraform will gaurantee a unique resource on your behalf:")]),e._v(" "),a("div",{staticClass:"language- extra-class"},[a("pre",{pre:!0,attrs:{class:"language-text"}},[a("code",[e._v('resource "aws_s3_bucket" "b" {\n  bucket_prefix = "my-dg-test-bucket"\n  acl    = "private"\n}\n')])])])])}),[],!1,null,null,null);t.default=s.exports}}]);